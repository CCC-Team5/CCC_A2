{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-brisbane",
   "metadata": {},
   "outputs": [],
   "source": [
    "# couchbd_settings\n",
    "address = 'localhost:15984'\n",
    "username = 'admin'\n",
    "password = '123456'\n",
    "tweets = 'raw_tweets'\n",
    "user = 'user_list'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-amateur",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from collections import defaultdict\n",
    "import couchdb\n",
    "import re\n",
    "class CouchDBHandler:\n",
    "    def __init__(self, username, password, address, dbname):\n",
    "        self.db = couchdb.Server('http://' + username + ':' + password + '@' + address)[dbname]\n",
    "        \n",
    "    def get_tweets(self, max_size: Optional[int]) -> list[str]:\n",
    "        tweet_timeline_dict = defaultdict(list)\n",
    "        tweet_stream_dict = defaultdict(list)\n",
    "        for i, doc_id in enumerate(self.db.view('_all_docs')):\n",
    "            if max_size:\n",
    "                if i > max_size:\n",
    "                    break\n",
    "            id_ = doc_id['id']\n",
    "            try:\n",
    "                year = self.db[id_]['stream']['created_at']\n",
    "                if year[:2] == '20':\n",
    "                    yr_created = year[:4]\n",
    "                else:  #close to today\n",
    "                    yr_created = '2022' \n",
    "                \n",
    "                tweet_stream_dict[yr_created].append(self.db[id_]['stream']['text'])\n",
    "            except:\n",
    "                year = self.db[id_]['timeline']['created_at']\n",
    "                \n",
    "                if year[:2] == '20':\n",
    "                    yr_created = year[:4]\n",
    "                else:  #close to today\n",
    "                    yr_created = '2022' \n",
    "                \n",
    "                tweet_timeline_dict[yr_created].append(self.db[id_]['timeline']['text'])\n",
    "        return tweet_timeline_dict, tweet_stream_dict\n",
    "    \n",
    "    #def send_tweets(tweets: dict[str, str]):\n",
    "        # self.db.save(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-shanghai",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_handler = CouchDBHandler(username, password, address, tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-punishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_timeline_dict,tweet_stream_dict = db_handler.get_tweets(max_size=145112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "improving-environment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 1644),\n",
       " ('to', 1147),\n",
       " ('a', 960),\n",
       " ('@', 924),\n",
       " ('and', 866),\n",
       " ('for', 777),\n",
       " ('of', 774),\n",
       " ('in', 655),\n",
       " ('you', 490),\n",
       " ('on', 486),\n",
       " ('is', 457),\n",
       " ('with', 444),\n",
       " ('I', 433),\n",
       " ('at', 342),\n",
       " ('my', 327),\n",
       " ('this', 309),\n",
       " ('.', 290),\n",
       " ('The', 266),\n",
       " ('your', 236),\n",
       " ('that', 234),\n",
       " ('&amp;', 229),\n",
       " ('are', 216),\n",
       " ('it', 199),\n",
       " ('be', 197),\n",
       " ('have', 193),\n",
       " ('all', 190),\n",
       " ('our', 189),\n",
       " ('from', 183),\n",
       " ('Australia', 168),\n",
       " ('-', 158),\n",
       " ('out', 152),\n",
       " ('by', 149),\n",
       " ('so', 142),\n",
       " ('up', 133),\n",
       " ('was', 132),\n",
       " ('Victoria,', 132),\n",
       " ('we', 131),\n",
       " ('new', 130),\n",
       " ('get', 121),\n",
       " ('Melbourne', 121),\n",
       " ('just', 115),\n",
       " ('me', 114),\n",
       " ('an', 113),\n",
       " ('A', 113),\n",
       " ('@Vibesfitness', 111),\n",
       " ('as', 105),\n",
       " ('but', 103),\n",
       " ('not', 100),\n",
       " ('day', 97),\n",
       " ('time', 96)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "#from nltk.corpus import stopwords \n",
    "#stopWords = set(stopwords.words('english')) \n",
    "from collections import Counter\n",
    "temp = [wrd for sub in tweet_timeline_dict['2018'] for wrd in sub.split()]\n",
    "#s = re.sub(r'[^a-zA-Z0-9]', '', string_value)\n",
    "#words = word_tokenize(temp) \n",
    "Counter2018 = Counter(temp)\n",
    "Counter2018.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "proper-logistics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 3964),\n",
       " ('to', 3004),\n",
       " ('a', 2391),\n",
       " ('and', 2204),\n",
       " ('@', 2073),\n",
       " ('of', 1889),\n",
       " ('in', 1858),\n",
       " ('for', 1792),\n",
       " ('I', 1237),\n",
       " ('you', 1194),\n",
       " ('is', 1174),\n",
       " ('with', 1116),\n",
       " ('on', 1114),\n",
       " ('&amp;', 1000),\n",
       " ('.', 866),\n",
       " ('at', 851),\n",
       " ('my', 815),\n",
       " ('this', 812),\n",
       " ('-', 734),\n",
       " ('Australia', 719),\n",
       " ('Victoria,', 643),\n",
       " ('your', 632),\n",
       " ('from', 604),\n",
       " ('our', 595),\n",
       " ('it', 587),\n",
       " ('that', 559),\n",
       " ('are', 557),\n",
       " ('The', 509),\n",
       " ('be', 501),\n",
       " ('was', 497)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp2019 = [wrd for sub in tweet_timeline_dict['2019'] for wrd in sub.split()]\n",
    "#s = re.sub(r'[^a-zA-Z0-9]', '', string_value)\n",
    "#words = word_tokenize(temp) \n",
    "Counter2019 = Counter(temp2019)\n",
    "Counter2019.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "accompanied-demographic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 7919),\n",
       " ('to', 6427),\n",
       " ('a', 5933),\n",
       " ('and', 4144),\n",
       " ('of', 4082),\n",
       " ('@', 3847),\n",
       " ('in', 3603),\n",
       " ('for', 3242),\n",
       " ('is', 2815),\n",
       " ('I', 2729),\n",
       " ('on', 2065),\n",
       " ('you', 2021),\n",
       " ('with', 1857),\n",
       " ('&amp;', 1772),\n",
       " ('this', 1766),\n",
       " ('.', 1684),\n",
       " ('Australia', 1663),\n",
       " ('my', 1600),\n",
       " ('at', 1585),\n",
       " ('-', 1556),\n",
       " ('Victoria,', 1529),\n",
       " ('from', 1299),\n",
       " ('be', 1264),\n",
       " ('are', 1235),\n",
       " ('that', 1217),\n",
       " ('have', 1151),\n",
       " ('it', 1146),\n",
       " ('our', 1057),\n",
       " ('your', 1040),\n",
       " ('Just', 1037)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp2020 = [wrd for sub in tweet_timeline_dict['2020'] for wrd in sub.split()]\n",
    "#s = re.sub(r'[^a-zA-Z0-9]', '', string_value)\n",
    "#words = word_tokenize(temp) \n",
    "Counter2020 = Counter(temp2020)\n",
    "Counter2020.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "parliamentary-medicaid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 22140),\n",
       " ('a', 18258),\n",
       " ('to', 16489),\n",
       " ('and', 10868),\n",
       " ('of', 10161),\n",
       " ('in', 9425),\n",
       " ('I', 8939),\n",
       " ('@', 8243),\n",
       " ('is', 7834),\n",
       " ('for', 7705),\n",
       " ('on', 5412),\n",
       " ('Just', 4812),\n",
       " ('this', 4722),\n",
       " ('you', 4393),\n",
       " ('my', 4284),\n",
       " ('with', 4230),\n",
       " ('posted', 4164),\n",
       " ('it', 3962),\n",
       " ('photo', 3886),\n",
       " ('at', 3680),\n",
       " ('&amp;', 3626),\n",
       " ('be', 3602),\n",
       " ('that', 3563),\n",
       " ('Australia', 3222),\n",
       " ('have', 3128),\n",
       " ('are', 3059),\n",
       " ('Victoria,', 2692),\n",
       " ('The', 2568),\n",
       " ('from', 2566),\n",
       " ('-', 2425)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp2021 = [wrd for sub in tweet_timeline_dict['2021'] for wrd in sub.split()]\n",
    "#s = re.sub(r'[^a-zA-Z0-9]', '', string_value)\n",
    "#words = word_tokenize(temp) \n",
    "Counter2021 = Counter(temp2021)\n",
    "Counter2021.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "infinite-artwork",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 25100),\n",
       " ('to', 17671),\n",
       " ('a', 16687),\n",
       " ('and', 11079),\n",
       " ('of', 11031),\n",
       " ('I', 10314),\n",
       " ('in', 9440),\n",
       " ('is', 8738),\n",
       " ('for', 7510),\n",
       " ('on', 5757),\n",
       " ('this', 5008),\n",
       " ('you', 4875),\n",
       " ('my', 4586),\n",
       " ('that', 4249),\n",
       " ('with', 4189),\n",
       " ('at', 3988),\n",
       " ('it', 3988),\n",
       " ('be', 3916),\n",
       " ('have', 3417),\n",
       " ('@', 3417),\n",
       " ('are', 3335),\n",
       " ('The', 2906),\n",
       " ('&amp;', 2858),\n",
       " ('was', 2828),\n",
       " ('from', 2711),\n",
       " ('-', 2685),\n",
       " ('but', 2678),\n",
       " ('not', 2587),\n",
       " ('me', 2499),\n",
       " ('all', 2411)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp2022 = [wrd for sub in tweet_timeline_dict['2022'] for wrd in sub.split()]\n",
    "#s = re.sub(r'[^a-zA-Z0-9]', '', string_value)\n",
    "#words = word_tokenize(temp) \n",
    "Counter2022 = Counter(temp2022)\n",
    "Counter2022.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "undefined-algebra",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 1618),\n",
       " ('to', 1155),\n",
       " ('a', 1134),\n",
       " ('I', 862),\n",
       " ('and', 733),\n",
       " ('of', 715),\n",
       " ('in', 645),\n",
       " ('is', 639),\n",
       " ('for', 534),\n",
       " ('you', 490),\n",
       " ('on', 355),\n",
       " ('that', 336),\n",
       " ('this', 326),\n",
       " ('are', 302),\n",
       " ('it', 296),\n",
       " ('be', 294),\n",
       " ('at', 281),\n",
       " ('my', 277),\n",
       " ('with', 273),\n",
       " ('have', 270),\n",
       " ('The', 226),\n",
       " ('-', 210),\n",
       " ('not', 199),\n",
       " ('was', 197),\n",
       " ('your', 182),\n",
       " ('just', 179),\n",
       " ('but', 174),\n",
       " ('all', 173),\n",
       " ('so', 169),\n",
       " ('as', 160)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp2022_stream = [wrd for sub in tweet_stream_dict['2022'] for wrd in sub.split()]\n",
    "#s = re.sub(r'[^a-zA-Z0-9]', '', string_value)\n",
    "#words = word_tokenize(temp) \n",
    "Counter2022_stream = Counter(temp2022_stream)\n",
    "Counter2022_stream.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "allied-visit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of timeline tweets in 2018:  3799\n",
      "number of timeline tweets in 2019:  7688\n",
      "number of timeline tweets in 2020:  17926\n",
      "number of timeline tweets in 2021:  53319\n",
      "number of timeline tweets in 2022:  56418\n",
      "number of stream tweets in 2022:  5963\n"
     ]
    }
   ],
   "source": [
    "print(\"number of timeline tweets in 2018: \", len(tweet_timeline_dict['2018']))\n",
    "print(\"number of timeline tweets in 2019: \", len(tweet_timeline_dict['2019']))\n",
    "print(\"number of timeline tweets in 2020: \", len(tweet_timeline_dict['2020']))\n",
    "print(\"number of timeline tweets in 2021: \", len(tweet_timeline_dict['2021']))\n",
    "print(\"number of timeline tweets in 2022: \", len(tweet_timeline_dict['2022']))\n",
    "print(\"number of stream tweets in 2022: \", len(tweet_stream_dict['2022']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-brief",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
